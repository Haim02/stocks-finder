# import time
# from app.services.screener_service import ScreenerService
# from app.services.news_scraper import NewsScraper
# from app.services.news_model import NewsModel
# from app.services.financial_service import FinancialAnalyzer
# from app.services.email_service import EmailService
# from app.data.mongo_client import MongoDB

# # ×”-URL ×©×œ×š ×-Finviz (×“×•×’××”)
# FINVIZ_SCREENER_URL = "https://finviz.com/screener.ashx?v=111&f=cap_mid,sh_avgvol_o500,sh_short_o10,ta_perf2_1w10o&ft=4"

# # ... (imports × ×©××¨×™× ××•×ª×• ×“×‘×¨)

# def run_news_driven_scan():
#     print("ğŸš€ Starting Scan (Hybrid Free Mode)...")

#     # 1. ×©×œ×™×¤×ª ××•×¢××“×™×
#     tickers = ScreenerService.get_candidates_from_url(FINVIZ_SCREENER_URL)

#     # × ×™×”×•×œ ×¨×©×™××ª ×”×× ×™×•×ª (×× ×”×¡×•×¨×§ × ×›×©×œ, ×”×•× ××—×–×™×¨ ×¨×©×™××ª ×’×™×‘×•×™ ×©×¨××™×ª ×‘×œ×•×’)
#     if not tickers:
#         print("ğŸ“­ No tickers found.")
#         return

#     scraper = NewsScraper()
#     model = NewsModel()
#     fin_analyzer = FinancialAnalyzer()

#     opportunities = []

#     for ticker in tickers:
#         print(f"ğŸ” Checking {ticker}...")

#         # ×. ××©×™×›×ª ×—×“×©×•×ª
#         stats, news_items = scraper.get_stock_data(ticker)
#         if not news_items: continue

#         # ×©××™×¨×” ×œ-DB
#         for item in news_items:
#             MongoDB.save_news_event(ticker, item)

#         # ×‘. ×“×™×¨×•×’ ×˜×§×¡×˜ (AI Model)
#         best_text_score = 0
#         best_headline = ""
#         for item in news_items:
#             score = model.predict_impact(item['headline'])
#             if score > best_text_score:
#                 best_text_score = score
#                 best_headline = item['headline']

#         # ×’. ×‘×“×™×§×ª ××™×›×•×ª
#         # ×”×•×¨×“×ª×™ ××ª ×”×¨×£ ×œ-60 ×›×“×™ ×©×ª×¨××” ×ª×•×¦××•×ª ×‘×”×ª×—×œ×”
#         if best_text_score >= 60:
#             print(f"   ğŸ”¥ Signal Found ({best_text_score}): {best_headline}")

#             # ×©×œ×™×¤×ª × ×ª×•× ×™× ×¤×™× × ×¡×™×™× (×”×’×¨×¡×” ×”××ª×•×§× ×ª)
#             fin_data = fin_analyzer.analyze(ticker)

#             if fin_data:
#                 opportunities.append({
#                     "ticker": ticker,
#                     "headline": best_headline,
#                     "score": best_text_score, # ×”×¦×™×•×Ÿ ××‘×•×¡×¡ ×¢×›×©×™×• ×¨×§ ×¢×œ ×”×˜×§×¡×˜
#                     "ml_score": best_text_score,
#                     "finnhub_sentiment": 50, # ×‘×¨×™×¨×ª ××—×“×œ
#                     "price": fin_data['current_price'],
#                     "financials": fin_data
#                 })

#         time.sleep(1)

#     # 4. ×“×™×•×•×—
#     if opportunities:
#         opportunities.sort(key=lambda x: x['score'], reverse=True)
#         print(f"ğŸ¯ Sending report with {len(opportunities)} opportunities.")
#         EmailService.send_report(opportunities)
#     else:
#         print("ğŸ’¤ No high-probability signals today.")

# if __name__ == "__main__":
#     run_news_driven_scan()



# import time
# from app.services.screener_service import ScreenerService
# from app.services.news_scraper import NewsScraper
# from app.services.news_model import NewsModel
# from app.services.financial_service import FinancialAnalyzer
# from app.services.email_service import EmailService
# from app.services.ai_service import AIService # ×”×•×¡×¤× ×• ××ª ×–×”
# from app.data.mongo_client import MongoDB

# # FINVIZ_SCREENER_URL = "https://finviz.com/screener.ashx?v=111&f=cap_smallover,sh_avgvol_o500,ta_rsi_nos50&ft=4"
# FINVIZ_SCREENER_URL = "https://finviz.com/screener.ashx?v=211&f=cap_midover%2Cfa_debteq_u1%2Cfa_roe_o20%2Csh_avgvol_o200%2Cta_beta_o1%2Cta_change_u%2Cta_highlow50d_nh%2Cta_sma200_pa%2Cta_sma50_pa&ft=4"
# # FINVIZ_SCREENER_URL = "https://finviz.com/screener.ashx?v=111&f=cap_smallover%2Csh_avgvol_o500%2Csh_short_o10%2Cta_beta_o1.5%2Cta_change_u%2Cta_perf2_1w10o%2Cta_sma20_pa&ft=4"

# def run_news_driven_scan():
#     print("ğŸš€ Starting AI-Powered Scan...")

#     tickers = ScreenerService.get_candidates_from_url(FINVIZ_SCREENER_URL)

#     if not tickers:
#         print("ğŸ“­ No tickers found.")
#         return

#     scraper = NewsScraper()
#     model = NewsModel()
#     fin_analyzer = FinancialAnalyzer()
#     ai_service = AIService() # ××ª×—×•×œ ×”-AI

#     opportunities = []

#     for ticker in tickers:
#         print(f"ğŸ” Analyzing {ticker}...")

#         # 1. ×—×“×©×•×ª
#         stats, news_items = scraper.get_stock_data(ticker)
#         if not news_items: continue

#         for item in news_items:
#             MongoDB.save_news_event(ticker, item)

#         # 2. ×¡×™× ×•×Ÿ ×—×“×©×•×ª
#         best_text_score = 0
#         best_headline = ""
#         for item in news_items:
#             score = model.predict_impact(item['headline'])
#             if score > best_text_score:
#                 best_text_score = score
#                 best_headline = item['headline']

#         # ×¡×£ ×¡×™× ×•×Ÿ (×”×•×¨×“×ª×™ ×œ-60 ×›×“×™ ×©×ª×¨××” ×ª×•×¦××•×ª)
#         if best_text_score >= 70:
#             print(f"   ğŸ”¥ Signal ({best_text_score}): {best_headline}")

#             # 3. × ×™×ª×•×— ×¤×™× × ×¡×™ ××¢××™×§ (yfinance)
#             fin_data = fin_analyzer.analyze(ticker)

#             # ... (Imports ××•×ª×• ×“×‘×¨)

# # ×‘×ª×•×š ×”×œ×•×œ××”, ×‘×—×œ×§ ×©×œ ×”-AI:

#             if fin_data:
#                 print(f"   ğŸ¤– Generating AI Analysis for {ticker}...")

#                 # ×§×¨×™××” ×œ-AI (××—×–×™×¨ ×¢×›×©×™×• ×©× ×™ ×—×œ×§×™×)
#                 ai_result = ai_service.analyze_stock(ticker, best_headline, fin_data)

#                 opportunities.append({
#                     "ticker": ticker,
#                     "headline": best_headline,
#                     "score": best_text_score,
#                     "price": fin_data['current_price'],
#                     "financials": fin_data,
#                     # ×”×–×¨×§×ª ×”×ª×•×¦××•×ª ××”-AI
#                     "ai_hebrew_desc": ai_result['hebrew_desc'],
#                     "ai_analysis": ai_result['analysis']
#                 })

#         time.sleep(1)

#     if opportunities:
#         opportunities.sort(key=lambda x: x['score'], reverse=True)
#         print(f"ğŸ¯ Sending report with {len(opportunities)} AI-analyzed stocks.")
#         EmailService.send_report(opportunities)
#     else:
#         print("ğŸ’¤ No opportunities found.")

# if __name__ == "__main__":
#     run_news_driven_scan()



# import time
# from app.services.screener_service import ScreenerService
# from app.services.news_scraper import NewsScraper
# from app.services.news_model import NewsModel
# from app.services.financial_service import FinancialAnalyzer
# from app.services.email_service import EmailService
# from app.services.ai_service import AIService
# from app.services.news_aggregator import NewsAggregator # ×”×•×¡×¤× ×• ××ª ×–×”
# from app.data.mongo_client import MongoDB

# # ×”×œ×™× ×§ ×”×¡×¤×¦×™×¤×™ ×©×œ×š ×œ-Finviz
# # FINVIZ_SCREENER_URL = "https://finviz.com/screener.ashx?v=211&f=cap_midover%2Cfa_debteq_u1%2Cfa_roe_o20%2Csh_avgvol_o200%2Cta_beta_o1%2Cta_change_u%2Cta_highlow50d_nh%2Cta_sma200_pa%2Cta_sma50_pa&ft=4"
# FINVIZ_SCREENER_URL = "https://finviz.com/screener.ashx?v=211&f=cap_smallover,fa_debteq_u1,fa_roe_o15,sh_avgvol_o300,sh_relvol_o1.5,sh_short_o5,ta_change_u,ta_rsi_nos50&ft=4"

# def run_news_driven_scan():
#     print("ğŸš€ Starting Hybrid Scan (Finviz Stocks + RSS News)...")

#     # --- ×—×œ×§ 1: ××™×¡×•×£ ×—×“×©×•×ª ×›×œ×œ×™×•×ª (RSS) ---
#     # ×–×” ×”×—×œ×§ ×”×—×“×© ×©××‘×™× ×›×•×ª×¨×•×ª FDA, ××™×–×•×’×™× ×•×›×•'
#     news_aggregator = NewsAggregator()
#     general_news = news_aggregator.fetch_last_24h_news()

#     # ×©××™×¨×ª ×”×—×“×©×•×ª ×”×›×œ×œ×™×•×ª ×œ-DB (×‘×©×‘×™×œ Train Model ×‘×¢×ª×™×“)
#     print("ğŸ’¾ Saving general news to database...")
#     for news in general_news:
#         ticker = news.get('ticker') or "GENERAL"
#         MongoDB.save_news_event(ticker, {
#             'headline': news['headline'],
#             'url': news['url']
#         })

#     # --- ×—×œ×§ 2: ×¡×¨×™×§×ª ×”×× ×™×•×ª ×©×œ×š ×-Finviz ---
#     # ×©×™××•×© ×‘×œ×™× ×§ ×©×œ×š
#     tickers = ScreenerService.get_candidates_from_url(FINVIZ_SCREENER_URL)

#     stock_opportunities = []

#     if tickers:
#         scraper = NewsScraper()
#         model = NewsModel()
#         fin_analyzer = FinancialAnalyzer()
#         ai_service = AIService()

#         for ticker in tickers:
#             print(f"ğŸ” Analyzing {ticker}...")

#             # 1. ××©×™×›×ª ×—×“×©×•×ª ×¡×¤×¦×™×¤×™×•×ª ×œ×× ×™×”
#             stats, news_items = scraper.get_stock_data(ticker)
#             if not news_items: continue

#             # ×©××™×¨×” ×œ-DB
#             for item in news_items:
#                 MongoDB.save_news_event(ticker, item)

#             # 2. ×¡×™× ×•×Ÿ ×•×“×™×¨×•×’ ×—×“×©×•×ª
#             best_text_score = 0
#             best_headline = ""
#             for item in news_items:
#                 score = model.predict_impact(item['headline'])
#                 if score > best_text_score:
#                     best_text_score = score
#                     best_headline = item['headline']

#             # ×¡×£ ×¡×™× ×•×Ÿ (70 ×•××¢×œ×”)
#             if best_text_score >= 70:
#                 print(f"   ğŸ”¥ Signal ({best_text_score}): {best_headline}")

#                 # 3. × ×™×ª×•×— ×¤×™× × ×¡×™
#                 fin_data = fin_analyzer.analyze(ticker)

#                 if fin_data:
#                     print(f"   ğŸ¤– Generating AI Analysis for {ticker}...")

#                     # 4. × ×™×ª×•×— AI
#                     ai_result = ai_service.analyze_stock(ticker, best_headline, fin_data)

#                     stock_opportunities.append({
#                         "ticker": ticker,
#                         "headline": best_headline,
#                         "score": best_text_score,
#                         "price": fin_data['current_price'],
#                         "financials": fin_data,
#                         "ai_hebrew_desc": ai_result['hebrew_desc'],
#                         "ai_analysis": ai_result['analysis']
#                     })

#             time.sleep(1) # ×”××ª× ×” ×§×¦×¨×” ×œ×× ×™×¢×ª ×—×¡×™××•×ª

#     # --- ×—×œ×§ 3: ×©×œ×™×—×ª ×”×“×•×— ×”××©×•×œ×‘ ---
#     # ×‘×•×“×§×™× ×× ×™×© ××©×”×• ×œ×©×œ×•×— (××• ×× ×™×•×ª ××• ×—×“×©×•×ª ×›×œ×œ×™×•×ª)
#     if stock_opportunities or general_news:
#         if stock_opportunities:
#             stock_opportunities.sort(key=lambda x: x['score'], reverse=True)

#         print(f"ğŸ¯ Sending report: {len(stock_opportunities)} Stocks & {len(general_news)} Headlines.")

#         # ×©×•×œ×—×™× ××ª ×©× ×™×”× ×œ××™×™×œ
#         EmailService.send_report(stock_opportunities, general_news)
#     else:
#         print("ğŸ’¤ No significant data found today.")

# if __name__ == "__main__":
#     run_news_driven_scan()


# import time
# from app.services.screener_service import ScreenerService
# from app.services.news_scraper import NewsScraper
# from app.services.news_model import NewsModel
# from app.services.financial_service import FinancialAnalyzer
# from app.services.email_service import EmailService
# from app.services.ai_service import AIService
# from app.services.news_aggregator import NewsAggregator
# from app.data.mongo_client import MongoDB

# # ×”×œ×™× ×§ ×”×˜×›× ×™ ×©×œ×š (Finviz)
# # FINVIZ_SCREENER_URL = "https://finviz.com/screener.ashx?v=111&f=cap_smallover,sh_avgvol_o300,ta_sma50_crossabove,ta_rsi_nos50&ft=4"
# # FINVIZ_SCREENER_URL = "https://finviz.com/screener.ashx?v=211&f=cap_smallover%2Csh_avgvol_o400%2Csh_relvol_o1.5%2Cta_rsi_nos50&ft=4"
# FINVIZ_SCREENER_URL = "https://finviz.com/screener.ashx?v=211&f=cap_smallover,fa_debteq_u1,fa_roe_o15,sh_avgvol_o300,sh_relvol_o1.5,sh_short_o5,ta_change_u,ta_rsi_nos50&ft=4"
# # ×œ×™× ×§ ×¨×—×‘ ×™×•×ª×¨ ×©×××¤×©×¨ ×œ×‘×•×˜ ×œ××¦×•× ×—×¦×™×•×ª ×©×œ 150
# # FINVIZ_SCREENER_URL = "https://finviz.com/screener.ashx?v=111&f=cap_smallover,sh_avgvol_o300,ta_sma20_sa50&ft=4"

# def run_news_driven_scan():
#     print("ğŸš€ Starting Super-Scan (Technical + Biotech News)...")

#     news_aggregator = NewsAggregator()

#     # 1. ××™×¡×•×£ ×›×•×ª×¨×•×ª ×›×œ×œ×™×•×ª ×œ××™×™×œ (RSS)
#     general_news = news_aggregator.fetch_last_24h_news()

#     # ×©××™×¨×” ×œ-DB
#     for news in general_news:
#         ticker = news.get('ticker') or "GENERAL"
#         MongoDB.save_news_event(ticker, {'headline': news['headline'], 'url': news['url']})

#     # 2. ××™×¡×•×£ ×¨×©×™××ª ×”×× ×™×•×ª ×œ× ×™×ª×•×—
#     target_tickers = set() # ×©×™××•×© ×‘-Set ××•× ×¢ ×›×¤×™×œ×•×™×•×ª

#     # ×' - ×× ×™×•×ª ×˜×›× ×™×•×ª ×-Finviz
#     finviz_tickers = ScreenerService.get_candidates_from_url(FINVIZ_SCREENER_URL)
#     if finviz_tickers:
#         print(f"ğŸ“ˆ Found {len(finviz_tickers)} Technical Breakout candidates.")
#         target_tickers.update(finviz_tickers)

#     # ×‘' - ×× ×™×•×ª ×‘×™×•×˜×§ ×¢× ×—×“×©×•×ª (×”×ª×•×¡×¤×ª ×”×—×“×©×”!)
#     biotech_tickers = news_aggregator.find_biotech_opportunities()
#     if biotech_tickers:
#         print(f"ğŸ§¬ Adding {len(biotech_tickers)} Biotech Stocks due to FDA/Trial news.")
#         target_tickers.update(biotech_tickers)

#     # ×”××¨×” ×—×–×¨×” ×œ×¨×©×™××”
#     final_tickers_list = list(target_tickers)

#     if not final_tickers_list:
#         print("ğŸ“­ No candidates found today.")
#         return

#     # 3. ×ª×”×œ×™×š ×”× ×™×ª×•×— ×”×¨×’×™×œ (×¢×•×‘×¨ ×¢×œ ×›×œ ×”×¨×©×™××” ×”×××•×—×“×ª)
#     stock_opportunities = []

#     scraper = NewsScraper()
#     model = NewsModel()
#     fin_analyzer = FinancialAnalyzer()
#     ai_service = AIService()

#     for ticker in final_tickers_list:
#         print(f"ğŸ” Analyzing {ticker}...")

#         # 1. ×—×“×©×•×ª
#         stats, news_items = scraper.get_stock_data(ticker)
#         if not news_items:
#             print(f"   Skipping {ticker} (No recent specific news found).")
#             continue

#         for item in news_items:
#             MongoDB.save_news_event(ticker, item)

#         # 2. ×“×™×¨×•×’
#         best_text_score = 0
#         best_headline = ""
#         for item in news_items:
#             score = model.predict_impact(item['headline'])
#             if score > best_text_score:
#                 best_text_score = score
#                 best_headline = item['headline']

#         # ×¡×£ ×¡×™× ×•×Ÿ (×× ×™×•×ª ×‘×™×•×˜×§ ×œ×¨×•×‘ ×™×§×‘×œ×• ×¦×™×•×Ÿ ×’×‘×•×” ×‘×’×œ×œ ××™×œ×•×ª ×”××¤×ª×—)
#         if best_text_score >= 60:
#             print(f"   ğŸ”¥ Signal ({best_text_score}): {best_headline}")

#             # 3. ×¤×™× × ×¡×™ + ×˜×›× ×™
#             fin_data = fin_analyzer.analyze(ticker)

#             if fin_data:
#                 print(f"   ğŸ¤– AI Analysis for {ticker}...")
#                 ai_result = ai_service.analyze_stock(ticker, best_headline, fin_data)

#                 stock_opportunities.append({
#                     "ticker": ticker,
#                     "headline": best_headline,
#                     "score": best_text_score,
#                     "price": fin_data['current_price'],
#                     "financials": fin_data,
#                     "ai_hebrew_desc": ai_result['hebrew_desc'],
#                     "ai_analysis": ai_result['analysis']
#                 })

#         time.sleep(1)

#     # 4. ×©×œ×™×—×ª ×“×•×—
#     if stock_opportunities or general_news:
#         stock_opportunities.sort(key=lambda x: x['score'], reverse=True)
#         print(f"ğŸ¯ Sending report: {len(stock_opportunities)} Stocks & {len(general_news)} Headlines.")
#         EmailService.send_report(stock_opportunities, general_news)
#     else:
#         print("ğŸ’¤ No significant opportunities found.")

# if __name__ == "__main__":
#     run_news_driven_scan()


# import time
# from app.services.screener_service import ScreenerService
# from app.services.news_scraper import NewsScraper
# from app.services.news_model import NewsModel
# from app.services.financial_service import FinancialAnalyzer
# from app.services.email_service import EmailService
# from app.services.ai_service import AIService
# from app.services.news_aggregator import NewsAggregator
# from app.data.mongo_client import MongoDB

# # ×œ×™× ×§ ×©×××¤×©×¨ ×œ××¦×•× ×’× ×ª×‘× ×™×•×ª ×˜×›× ×™×•×ª (××¨×—×™×‘ ××ª ×”×™×¨×™×¢×”)
# FINVIZ_SCREENER_URL = "https://finviz.com/screener.ashx?v=111&f=cap_smallover,sh_avgvol_o300,ta_sma20_sa50&ft=4"

# def run_hybrid_scan():
#     print("ğŸš€ Starting Hybrid Scan (News + Pure Technicals)...")

#     # 1. RSS ×›×œ×œ×™
#     news_aggregator = NewsAggregator()
#     general_news = news_aggregator.fetch_last_24h_news()

#     # 2. ××™×¡×•×£ ×× ×™×•×ª
#     target_tickers = set()

#     # ×' - ×¤×™× ×‘×™×– (×”×‘×¡×™×¡)
#     finviz_tickers = ScreenerService.get_candidates_from_url(FINVIZ_SCREENER_URL)
#     if finviz_tickers:
#         print(f"ğŸ“ˆ Scanned {len(finviz_tickers)} charts from Finviz.")
#         target_tickers.update(finviz_tickers)

#     # ×‘' - ×‘×™×•×˜×§
#     biotech_tickers = news_aggregator.find_biotech_opportunities()
#     if biotech_tickers:
#         target_tickers.update(biotech_tickers)

#     final_tickers_list = list(target_tickers)
#     stock_opportunities = []

#     scraper = NewsScraper()
#     model = NewsModel()
#     fin_analyzer = FinancialAnalyzer()
#     ai_service = AIService()

#     print(f"ğŸ” Deep analyzing {len(final_tickers_list)} candidates...")

#     for ticker in final_tickers_list:
#         # 1. ×§×•×“× ×›×œ - × ×™×ª×•×— ×¤×™× × ×¡×™ ×•×˜×›× ×™
#         # ×× ×—× ×• ×¢×•×©×™× ××ª ×–×” *×œ×¤× ×™* ×”×—×“×©×•×ª, ×›×™ ××•×œ×™ ×–×” ×˜×›× ×™ ×˜×”×•×¨
#         fin_data = fin_analyzer.analyze(ticker)

#         if not fin_data:
#             continue

#         technical_signal = fin_data.get('technical_signal')

#         # 2. ×‘×“×™×§×ª ×—×“×©×•×ª
#         stats, news_items = scraper.get_stock_data(ticker)

#         # ×—×™×©×•×‘ ×¦×™×•×Ÿ ×—×“×©×•×ª (×× ×™×©)
#         news_score = 0
#         best_headline = "×œ×œ× ×—×“×©×•×ª ×˜×¨×™×•×ª (××™×ª×•×ª ×˜×›× ×™ ×‘×œ×‘×“)"

#         if news_items:
#             for item in news_items:
#                 MongoDB.save_news_event(ticker, item) # ×©××™×¨×” ×œ×œ××™×“×”
#                 score = model.predict_impact(item['headline'])
#                 if score > news_score:
#                     news_score = score
#                     best_headline = item['headline']

#         # --- ×¢×›×©×™×• ×”×”×—×œ×˜×”: ×”×× ×œ×”×•×¡×™×£ ××ª ×”×× ×™×”? ---

#         should_add = False
#         reason = ""

#         # ××¡×œ×•×œ ×': ×™×© ×—×“×©×•×ª ×—×–×§×•×ª
#         if news_score >= 60:
#             should_add = True
#             reason = "News"

#         # ××¡×œ×•×œ ×‘': ××™×Ÿ ×—×“×©×•×ª, ××‘×œ ×™×© ××™×ª×•×ª ×˜×›× ×™ ×—×–×§ (×”×‘×§×©×” ×©×œ×š!)
#         elif technical_signal is not None:
#             should_add = True
#             reason = "Technical"
#             # × ×™×ª×Ÿ ×¦×™×•×Ÿ ××œ××›×•×ª×™ ×›×“×™ ×©×™×•×¤×™×¢ ×‘×“×•×—, ××‘×œ × ××•×š ×™×•×ª×¨ ××—×“×©×•×ª ×œ×•×”×˜×•×ª
#             news_score = 55

#         if should_add:
#             print(f"   âœ… Found Opportunity: {ticker} | Reason: {reason}")
#             if reason == "Technical":
#                 print(f"      Signal: {technical_signal}")

#             # ×× ×–×” ×˜×›× ×™ ×‘×œ×‘×“, ××™×Ÿ ×¦×•×¨×š ×‘-AI ×›×‘×“ ×œ× ×™×ª×•×— ×˜×§×¡×˜, × ×—×¡×•×š ×–××Ÿ
#             ai_analysis_text = "××™×ª×•×ª ×˜×›× ×™ ×˜×”×•×¨. ×”××¢×¨×›×ª ×–×™×”×ª×” ×ª×‘× ×™×ª ××—×™×¨ ××©××¢×•×ª×™×ª ×œ×œ× ×—×“×©×•×ª ×™×©×™×¨×•×ª."
#             if reason == "News":
#                  ai_res = ai_service.analyze_stock(ticker, best_headline, fin_data)
#                  ai_analysis_text = ai_res['analysis']

#             stock_opportunities.append({
#                 "ticker": ticker,
#                 "headline": best_headline,
#                 "score": news_score,
#                 "price": fin_data['current_price'],
#                 "financials": fin_data,
#                 "ai_hebrew_desc": "×”×–×“×× ×•×ª ××¡×—×¨", # ××¤×©×¨ ×œ×©×¤×¨ ×¢× AI ×× ×¨×•×¦×™×
#                 "ai_analysis": ai_analysis_text
#             })

#         time.sleep(1)

#     # 4. ×©×œ×™×—×ª ×“×•×—
#     if stock_opportunities or general_news:
#         stock_opportunities.sort(key=lambda x: x['score'], reverse=True)
#         EmailService.send_report(stock_opportunities, general_news)
#         print("Done.")
#     else:
#         print("No opportunities.")

# if __name__ == "__main__":
#     run_hybrid_scan()


# import time
# from app.services.screener_service import ScreenerService
# from app.services.news_scraper import NewsScraper
# from app.services.news_model import NewsModel
# from app.services.financial_service import FinancialAnalyzer
# from app.services.email_service import EmailService
# from app.services.ai_service import AIService
# from app.services.news_aggregator import NewsAggregator
# from app.data.mongo_client import MongoDB

# # ×œ×™× ×§ ×¨×—×‘ ×™×•×ª×¨ ×›×“×™ ×œ×ª×¤×•×¡ ××ª ×”-150
# FINVIZ_SCREENER_URL = "https://finviz.com/screener.ashx?v=111&f=cap_smallover,sh_avgvol_o300,ta_sma20_sa50&ft=4"

# def run_hybrid_scan():
#     print("ğŸš€ Starting FULL Hybrid Scan...")

#     news_aggregator = NewsAggregator()
#     general_news = news_aggregator.fetch_last_24h_news()

#     target_tickers = set()

#     # 1. ××™×¡×•×£ ××¤×™× ×‘×™×–
#     finviz_tickers = ScreenerService.get_candidates_from_url(FINVIZ_SCREENER_URL)
#     if finviz_tickers:
#         print(f"ğŸ“ˆ Candidates from Finviz: {len(finviz_tickers)}")
#         target_tickers.update(finviz_tickers)

#     # 2. ××™×¡×•×£ ××‘×™×•×˜×§
#     biotech_tickers = news_aggregator.find_biotech_opportunities()
#     if biotech_tickers:
#         target_tickers.update(biotech_tickers)

#     final_tickers_list = list(target_tickers)
#     stock_opportunities = []

#     scraper = NewsScraper()
#     model = NewsModel()
#     fin_analyzer = FinancialAnalyzer()
#     ai_service = AIService() # ×—×•×‘×” ×©×™×”×™×” ××•×’×“×¨

#     print(f"ğŸ” Analyzing {len(final_tickers_list)} stocks...")

#     for ticker in final_tickers_list:
#         # ×. × ×™×ª×•×— ×¤×™× × ×¡×™ ××œ× (×›×•×œ×œ QoQ ×•-SMA150)
#         fin_data = fin_analyzer.analyze(ticker)
#         if not fin_data: continue

#         technical_signal = fin_data.get('technical_signal')

#         # ×‘. ×‘×“×™×§×ª ×—×“×©×•×ª
#         stats, news_items = scraper.get_stock_data(ticker)
#         news_score = 0
#         best_headline = "××™×ª×•×ª ×˜×›× ×™: " + (technical_signal if technical_signal else "×œ×œ× ×—×“×©×•×ª")

#         real_headline_found = False
#         if news_items:
#             for item in news_items:
#                 MongoDB.save_news_event(ticker, item)
#                 score = model.predict_impact(item['headline'])
#                 if score > news_score:
#                     news_score = score
#                     best_headline = item['headline']
#                     real_headline_found = True

#         # ×’. ×§×‘×œ×ª ×”×—×œ×˜×”
#         should_add = False
#         reason = ""

#         if news_score >= 60:
#             should_add = True
#             reason = "News"
#         elif technical_signal is not None:
#             should_add = True
#             reason = "Technical"
#             if not real_headline_found:
#                 news_score = 55 # ×¦×™×•×Ÿ ××œ××›×•×ª×™ ×›×“×™ ×©×™×™×›× ×¡ ×œ×˜×‘×œ×”

#         if should_add:
#             print(f"   âœ… Found {ticker} ({reason})")

#             # ×“. ×”×¤×¢×œ×ª AI - ×—×•×‘×” ×’× ×œ×˜×›× ×™ ×›×“×™ ×œ×§×‘×œ ×ª×™××•×¨ ×—×‘×¨×”!
#             # ×× ××™×Ÿ ×›×•×ª×¨×ª ×××™×ª×™×ª, × ×©×œ×— ×œ-AI ××ª ×”××™×ª×•×ª ×”×˜×›× ×™ ×›"×›×•×ª×¨×ª" ×œ× ×™×ª×•×—
#             prompt_headline = best_headline
#             if reason == "Technical" and not real_headline_found:
#                 prompt_headline = f"Technical Signal: {technical_signal}. Company analysis needed."

#             ai_result = ai_service.analyze_stock(ticker, prompt_headline, fin_data)

#             stock_opportunities.append({
#                 "ticker": ticker,
#                 "headline": best_headline,
#                 "score": news_score,
#                 "price": fin_data['current_price'],
#                 "financials": fin_data, # ××›×™×œ ×¢×›×©×™×• ××ª ×›×œ ×”-QoQ
#                 "ai_hebrew_desc": ai_result['hebrew_desc'], # ×”×ª×™××•×¨ ×‘×¢×‘×¨×™×ª
#                 "ai_analysis": ai_result['analysis']
#             })

#         time.sleep(1)

#     if stock_opportunities or general_news:
#         stock_opportunities.sort(key=lambda x: x['score'], reverse=True)
#         EmailService.send_report(stock_opportunities, general_news)
#         print("Done.")
#     else:
#         print("No opportunities found.")

# if __name__ == "__main__":
#     run_hybrid_scan()



import time
from app.services.screener_service import ScreenerService
from app.services.news_scraper import NewsScraper
from app.services.news_model import NewsModel
from app.services.financial_service import FinancialAnalyzer
from app.services.email_service import EmailService
from app.services.ai_service import AIService
from app.services.news_aggregator import NewsAggregator
from app.data.mongo_client import MongoDB

# ×œ×™× ×§ ×¨×—×‘ ×™×•×ª×¨ ×›×“×™ ×œ×ª×¤×•×¡ ××ª ×”-150
FINVIZ_SCREENER_URL = "https://finviz.com/screener.ashx?v=111&f=cap_smallover,sh_avgvol_o300,ta_sma20_sa50&ft=4"

def run_hybrid_scan():
    print("ğŸš€ Starting Hybrid Scan (With Smart Filter)...")

    news_aggregator = NewsAggregator()
    general_news = news_aggregator.fetch_last_24h_news()

    target_tickers = set()

    # 1. ××™×¡×•×£ ××¤×™× ×‘×™×–
    finviz_tickers = ScreenerService.get_candidates_from_url(FINVIZ_SCREENER_URL)
    if finviz_tickers:
        print(f"ğŸ“ˆ Candidates from Finviz: {len(finviz_tickers)}")
        target_tickers.update(finviz_tickers)

    # 2. ××™×¡×•×£ ××‘×™×•×˜×§
    biotech_tickers = news_aggregator.find_biotech_opportunities()
    if biotech_tickers:
        target_tickers.update(biotech_tickers)

    final_tickers_list = list(target_tickers)
    stock_opportunities = []

    scraper = NewsScraper()
    model = NewsModel()
    fin_analyzer = FinancialAnalyzer()
    ai_service = AIService()

    print(f"ğŸ” Analyzing {len(final_tickers_list)} stocks...")

    for ticker in final_tickers_list:

        # --- ×¡×™× ×•×Ÿ ×—×“×©: ×”×× ×›×‘×¨ ×©×œ×—× ×• ××ª ×–×” ×œ××—×¨×•× ×”? ---
        if MongoDB.was_sent_recently(ticker, days=3):
            print(f"   â­ï¸ Skipping {ticker} (Sent in last 3 days).")
            continue
        # -----------------------------------------------

        # ×. × ×™×ª×•×— ×¤×™× × ×¡×™ ××œ×
        fin_data = fin_analyzer.analyze(ticker)
        if not fin_data: continue

        technical_signal = fin_data.get('technical_signal')

        # ×‘. ×‘×“×™×§×ª ×—×“×©×•×ª
        stats, news_items = scraper.get_stock_data(ticker)
        news_score = 0
        best_headline = "××™×ª×•×ª ×˜×›× ×™: " + (technical_signal if technical_signal else "×œ×œ× ×—×“×©×•×ª")

        real_headline_found = False
        if news_items:
            for item in news_items:
                MongoDB.save_news_event(ticker, item)
                score = model.predict_impact(item['headline'])
                if score > news_score:
                    news_score = score
                    best_headline = item['headline']
                    real_headline_found = True

        # ×’. ×§×‘×œ×ª ×”×—×œ×˜×”
        should_add = False
        reason = ""

        if news_score >= 60:
            should_add = True
            reason = "News"
        elif technical_signal is not None:
            should_add = True
            reason = "Technical"
            if not real_headline_found:
                news_score = 55 # ×¦×™×•×Ÿ ××œ××›×•×ª×™

        if should_add:
            print(f"   âœ… Found {ticker} ({reason})")

            # --- ×ª×™×¢×•×“ ×—×“×©: ×©×•××¨×™× ×©×©×œ×—× ×• ××ª ×”×× ×™×” ---
            MongoDB.log_sent_alert(ticker, reason)
            # -----------------------------------------

            # ×“. ×”×¤×¢×œ×ª AI
            prompt_headline = best_headline
            if reason == "Technical" and not real_headline_found:
                prompt_headline = f"Technical Signal: {technical_signal}. Company analysis needed."

            ai_result = ai_service.analyze_stock(ticker, prompt_headline, fin_data)

            stock_opportunities.append({
                "ticker": ticker,
                "headline": best_headline,
                "score": news_score,
                "price": fin_data['current_price'],
                "financials": fin_data,
                "ai_hebrew_desc": ai_result['hebrew_desc'],
                "ai_analysis": ai_result['analysis']
            })

        time.sleep(1)

    if stock_opportunities or general_news:
        stock_opportunities.sort(key=lambda x: x['score'], reverse=True)
        EmailService.send_report(stock_opportunities, general_news)
        print("Done.")
    else:
        print("No NEW opportunities found (Spam filter active).")

if __name__ == "__main__":
    run_hybrid_scan()