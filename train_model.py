# import pandas as pd
# import yfinance as yf
# from datetime import timedelta
# from app.data.mongo_client import MongoDB
# from app.services.news_model import NewsModel

# def get_price_change(ticker, date_obj):
#     """×‘×•×“×§ ×× ×”×× ×™×” ×¢×œ×ª×” ×‘×™×•××™×™× ×©××—×¨×™ ×”×ª××¨×™×š"""
#     try:
#         start = date_obj
#         end = date_obj + timedelta(days=5)
#         df = yf.download(ticker, start=start, end=end, progress=False)
#         if len(df) < 3: return None

#         close_prices = df['Close']
#         start_price = close_prices.iloc[0]
#         end_price = close_prices.iloc[2] # T+2

#         return (end_price - start_price) / start_price
#     except:
#         return None

# def main():
#     print("ğŸ“ Starting Training Process...")
#     db_items = MongoDB.get_unlabeled_data()

#     training_data = []

#     for item in db_items:
#         # ×‘×“×™×§×ª ××” ×§×¨×” ×‘××¦×™××•×ª
#         change = get_price_change(item['ticker'], item['news_date'])

#         if change is not None:
#             # ×ª×™×•×’: 1 ×× ×¢×œ×ª×” ××¢×œ 2%, ××—×¨×ª 0
#             is_winner = 1 if change > 0.02 else 0

#             training_data.append({
#                 "headline": item['headline'],
#                 "is_winner": is_winner
#             })

#             # ×¡×™××•×Ÿ ×‘-DB ×©×”×¨×©×•××” ×¢×•×‘×“×”
#             # (×›××Ÿ ×™×© ×œ×”×•×¡×™×£ ×§×•×“ ×œ×¢×“×›×•×Ÿ ×”××¡××š ×‘-Mongo ×œ-processed=True)

#     if len(training_data) > 50:
#         df = pd.DataFrame(training_data)
#         model = NewsModel()
#         model.train(df)
#     else:
#         print(f"âš ï¸ Not enough data yet ({len(training_data)} samples). Need at least 50.")

# if __name__ == "__main__":
#     main()



# import pandas as pd
# import yfinance as yf
# from datetime import timedelta
# from sklearn.feature_extraction.text import TfidfVectorizer
# from sklearn.ensemble import RandomForestClassifier
# import joblib
# import os
# from app.data.mongo_client import MongoDB

# # ×”×’×“×¨×•×ª ×œ××™××•×Ÿ
# MODEL_PATH = "app/models/news_classifier.pkl"
# VECTORIZER_PATH = "app/models/tfidf_vectorizer.pkl"
# MIN_SAMPLES_TO_TRAIN = 50  # ×œ× ××ª×—×™×œ×™× ×œ×××Ÿ ×œ×¤× ×™ ×©×™×© 50 ×“×•×’×××•×ª

# def get_price_change(ticker, date):
#     """
#     ×‘×•×“×§ ×”×× ×”××—×™×¨ ×¢×œ×” ×‘×™×•××™×™× ×©×œ××—×¨ ×”×—×“×©×•×ª.
#     ××—×–×™×¨ 1 ×× ×¢×œ×” ××¢×œ 2% (×—×“×©×” ×˜×•×‘×”), ××—×¨×ª 0.
#     """
#     try:
#         # ×‘×“×™×§×ª ××—×™×¨ ×‘×˜×•×•×— ×©×œ 3 ×™××™× ××”×—×“×©×”
#         start_date = date
#         end_date = date + timedelta(days=3)

#         stock = yf.Ticker(ticker)
#         df = stock.history(start=start_date, end=end_date)

#         if len(df) < 2:
#             return None # ××™×Ÿ ××¡×¤×™×§ × ×ª×•× ×™× (××•×œ×™ ×¡×•×¤"×©)

#         open_price = df['Open'].iloc[0]
#         close_price = df['Close'].iloc[-1]

#         # ×—×™×©×•×‘ ××—×•×– ×©×™× ×•×™
#         pct_change = (close_price - open_price) / open_price

#         # ×”×ª×™×•×’: ×× ×”×× ×™×” ×¢×œ×ª×” ×™×•×ª×¨ ×-2%, × ×—×©×™×‘ ××ª ×–×” ×›×—×“×©×” ×—×™×•×‘×™×ª (1)
#         if pct_change > 0.02:
#             return 1
#         return 0

#     except Exception as e:
#         print(f"âš ï¸ Error checking price for {ticker}: {e}")
#         return None

# def train_model():
#     print("ğŸ§  Starting Model Training process...")

#     # 1. ×©×œ×™×¤×ª ×—×“×©×•×ª ×—×“×©×•×ª ××”-DB
#     raw_data = MongoDB.get_unlabeled_data()

#     if not raw_data:
#         print("ğŸ“­ No new data to process.")
#         return

#     print(f"ğŸ“¥ Processing {len(raw_data)} new news items...")

#     labeled_news = []
#     labels = []

#     for item in raw_data:
#         ticker = item.get('ticker')

#         # --- ×”×©×™× ×•×™ ×”×—×©×•×‘: ×¡×™× ×•×Ÿ ×—×“×©×•×ª ×›×œ×œ×™×•×ª ---
#         # ×× ××™×Ÿ ×˜×™×§×¨ ××• ×©×–×” GENERAL, ××™ ××¤×©×¨ ×œ×‘×“×•×§ ××—×™×¨ ×× ×™×”
#         if not ticker or ticker == "GENERAL":
#             # × ×¡××Ÿ ×›××¢×•×‘×“ ×›×“×™ ×©×œ× ×™×•×¤×™×¢ ×©×•×‘, ××‘×œ ×œ× × ×œ××“ ××–×”
#             MongoDB.mark_as_processed(item['_id'])
#             continue

#         # ×‘×“×™×§×ª "×”×ª×©×•×‘×” ×”× ×›×•× ×”" (×”×× ×”××—×™×¨ ×¢×œ×”?)
#         label = get_price_change(ticker, item['news_date'])

#         if label is not None:
#             labeled_news.append(item['headline'])
#             labels.append(label)
#             print(f"   âœ… Labeled: {ticker} -> {label}")

#         # ×¡×™××•×Ÿ ×‘-DB ×©×”×—×“×©×” ×”×–×• ×˜×•×¤×œ×”
#         MongoDB.mark_as_processed(item['_id'])

#     # ×× ××™×Ÿ ××¡×¤×™×§ ×“×•×’×××•×ª ×—×“×©×•×ª ×œ××™××•×Ÿ
#     if len(labeled_news) < 10:
#         print("â³ Not enough labeled data yet to update model. Waiting for more.")
#         return

#     # 2. ×˜×¢×™× ×ª × ×ª×•× ×™× ×™×©× ×™× (×× ×™×©) ×•×©×™×œ×•×‘ ×¢× ×”×—×“×©×™×
#     # (×‘×’×¨×¡×” ××ª×§×“××ª × ×©××•×¨ ×“××˜×”-×¡×˜ ×‘×§×•×‘×¥ CSV × ×¤×¨×“, ×›×¨×’×¢ × ×××Ÿ ××—×“×© ×¢×œ ××” ×©×™×©)

#     # ×‘×“×™×§×” ×”×× ×™×© ×œ× ×• ××¡×¤×™×§ ×“××˜×” ×›×•×œ×œ ×‘×¡×š ×”×›×œ
#     if len(labeled_news) < MIN_SAMPLES_TO_TRAIN:
#          print(f"âš ï¸ Collected {len(labeled_news)} samples total. Need {MIN_SAMPLES_TO_TRAIN} to start training.")
#          return

#     # 3. ××™××•×Ÿ ×”××•×“×œ
#     print(f"ğŸ“ Training model on {len(labeled_news)} samples...")

#     vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)
#     X = vectorizer.fit_transform(labeled_news)
#     y = labels

#     model = RandomForestClassifier(n_estimators=100, random_state=42)
#     model.fit(X, y)

#     # 4. ×©××™×¨×ª ×”××•×“×œ
#     if not os.path.exists("app/models"):
#         os.makedirs("app/models")

#     joblib.dump(model, MODEL_PATH)
#     joblib.dump(vectorizer, VECTORIZER_PATH)

#     print("ğŸš€ Model updated and saved successfully!")

# if __name__ == "__main__":
#     train_model()



import pandas as pd
import yfinance as yf
from datetime import datetime, timedelta
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
import joblib
import os
import pytz
from app.data.mongo_client import MongoDB

# ×”×’×“×¨×•×ª ×œ××™××•×Ÿ
MODEL_PATH = "app/models/news_classifier.pkl"
VECTORIZER_PATH = "app/models/tfidf_vectorizer.pkl"
MIN_SAMPLES_TO_TRAIN = 10

def get_price_change(ticker, date):
    """
    ×‘×•×“×§ ×”×× ×”××—×™×¨ ×¢×œ×” ×‘-3 ×”×™××™× ×©×œ××—×¨ ×”×—×“×©×•×ª.
    """
    try:
        if date.tzinfo is None:
            date = date.replace(tzinfo=pytz.utc)

        start_date = date
        end_date = date + timedelta(days=4)

        stock = yf.Ticker(ticker)
        df = stock.history(start=start_date.strftime('%Y-%m-%d'),
                           end=end_date.strftime('%Y-%m-%d'))

        if df.empty or len(df) < 2:
            return None

        open_price = df['Open'].iloc[0]
        close_price = df['Close'].iloc[-1]
        max_price = df['High'].max()

        change_close = (close_price - open_price) / open_price
        change_high = (max_price - open_price) / open_price

        # ×ª× ××™ ×”×¦×œ×—×”: ×¢×œ×™×™×” ×©×œ 3% ×‘×¡×’×™×¨×” ××• ×–×™× ×•×§ ×©×œ 5% ×‘××”×œ×š ×”×™×•×
        if change_close > 0.03 or change_high > 0.05:
            return 1
        return 0

    except Exception as e:
        return None

def train_model():
    print("ğŸ§  Starting Training Process (Duplicates Filter Enabled)...")

    raw_data = MongoDB.get_unlabeled_data()

    if not raw_data:
        print("ğŸ“­ Database is empty or all items processed.")
        return

    print(f"ğŸ“¥ Found {len(raw_data)} items. Filtering duplicates & mature data...")

    labeled_news = []
    labels = []

    # --- ×”×ª×™×§×•×Ÿ: ×–×™×›×¨×•×Ÿ ×œ×›×•×ª×¨×•×ª ×©×¨××™× ×• ×›×‘×¨ ---
    seen_headlines = set()

    processed_count = 0
    skipped_count = 0
    duplicates_count = 0 # ××•× ×” ×›×¤×™×œ×•×™×•×ª

    now = datetime.now(pytz.utc)

    for item in raw_data:
        ticker = item.get('ticker')
        headline = item.get('headline')

        # 1. ×¡×™× ×•×Ÿ ×›×¤×™×œ×•×™×•×ª ××™×™×“×™
        if headline in seen_headlines:
            # ××¡×× ×™× ×›×˜×•×¤×œ ×›×“×™ ×©×œ× ×™×•×¤×™×¢ ×‘×¤×¢× ×”×‘××”, ××‘×œ ×œ× ×œ×•××“×™× ××–×” ×©×•×‘
            MongoDB.mark_as_processed(item['_id'])
            duplicates_count += 1
            continue

        # ×”×•×¡×¤×” ×œ×–×™×›×¨×•×Ÿ
        seen_headlines.add(headline)

        # ×”××¨×ª ×ª××¨×™×š
        news_date = item.get('news_date')
        if isinstance(news_date, str):
            try:
                news_date = datetime.fromisoformat(news_date)
            except:
                MongoDB.mark_as_processed(item['_id'])
                continue

        if news_date.tzinfo is None:
            news_date = news_date.replace(tzinfo=pytz.utc)

        # 2. ×”×× ×¢×‘×¨×• 3 ×™××™×?
        if (now - news_date).days < 3:
            skipped_count += 1
            continue

        if not ticker or ticker == "GENERAL":
            MongoDB.mark_as_processed(item['_id'])
            continue

        # 3. ×‘×“×™×§×ª ××—×™×¨
        label = get_price_change(ticker, news_date)

        if label is not None:
            labeled_news.append(headline)
            labels.append(label)
            print(f"   âœ… Learned: {ticker} -> {label}") # ×™×“×¤×™×¡ ×›×œ ×›×•×ª×¨×ª ×¨×§ ×¤×¢× ××—×ª
            processed_count += 1
        else:
            print(f"   âš ï¸ No data for {ticker}, skipping.")

        # ×¡×™××•×Ÿ ×‘-DB
        MongoDB.mark_as_processed(item['_id'])

    print(f"\nğŸ“Š Summary:")
    print(f"   - Original items: {len(raw_data)}")
    print(f"   - Duplicates Removed: {duplicates_count}")
    print(f"   - Too new (Skipped): {skipped_count}")
    print(f"   - Successfully Trained: {processed_count}")

    if len(labeled_news) < MIN_SAMPLES_TO_TRAIN:
        print(f"â³ Not enough unique data yet ({len(labeled_news)}/{MIN_SAMPLES_TO_TRAIN}).")
        return

    print(f"ğŸ“ Training model on {len(labeled_news)} unique samples...")

    vectorizer = TfidfVectorizer(stop_words='english', max_features=2000)
    X = vectorizer.fit_transform(labeled_news)
    y = labels

    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X, y)

    if not os.path.exists("app/models"):
        os.makedirs("app/models")

    joblib.dump(model, MODEL_PATH)
    joblib.dump(vectorizer, VECTORIZER_PATH)

    print("ğŸš€ Model successfully updated without duplicates!")

if __name__ == "__main__":
    train_model()